{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c4becf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyacinth\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Hyacinth\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Hyacinth\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hyacinth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hyacinth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Hyacinth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, BertTokenizerFast,DistilBertTokenizerFast\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "words = set(nltk.corpus.words.words())\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pytorch_lightning as pl\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b178c783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119c7dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9aec2da3-f296-4e6a-b58d-c27889d0220e</td>\n",
       "      <td>Kenny Dellinger</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AFdZu...</td>\n",
       "      <td>This app is horrible! It shows you the ranking...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>2021-10-28 15:06:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>steptracker.healthandfitness.walkingtracker.pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975cf970-c461-4a72-9a34-c4cabb3b4f41</td>\n",
       "      <td>Louis Le</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/AItbvm...</td>\n",
       "      <td>Everything is decent but need at option to set...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>2021-01-02 17:57:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>steptracker.healthandfitness.walkingtracker.pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adca097b-fdec-46ff-8467-9f0c62332d37</td>\n",
       "      <td>Erik Erikson</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AFdZu...</td>\n",
       "      <td>Don't bother! This app is useless. 1st day I u...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>2021-01-02 13:50:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>steptracker.healthandfitness.walkingtracker.pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6bf89956-c26f-47d1-ad23-d2bb7ff725db</td>\n",
       "      <td>John Connor</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/AItbvm...</td>\n",
       "      <td>Works great, but I turned off all voice prompt...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>2021-06-06 12:13:53</td>\n",
       "      <td>Hi John, sorry for the inconvenience.\\nYou can...</td>\n",
       "      <td>2021-06-11 10:17:13</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>steptracker.healthandfitness.walkingtracker.pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0c8203a4-08b4-408f-9157-84e66393bfdd</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dtay away from this app! The app never turned ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-18 17:37:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>steptracker.healthandfitness.walkingtracker.pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  9aec2da3-f296-4e6a-b58d-c27889d0220e  Kenny Dellinger   \n",
       "1  975cf970-c461-4a72-9a34-c4cabb3b4f41         Louis Le   \n",
       "2  adca097b-fdec-46ff-8467-9f0c62332d37     Erik Erikson   \n",
       "3  6bf89956-c26f-47d1-ad23-d2bb7ff725db      John Connor   \n",
       "4  0c8203a4-08b4-408f-9157-84e66393bfdd    A Google user   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/AFdZu...   \n",
       "1  https://play-lh.googleusercontent.com/a/AItbvm...   \n",
       "2  https://play-lh.googleusercontent.com/a-/AFdZu...   \n",
       "3  https://play-lh.googleusercontent.com/a/AItbvm...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  This app is horrible! It shows you the ranking...      1             11   \n",
       "1  Everything is decent but need at option to set...      1              9   \n",
       "2  Don't bother! This app is useless. 1st day I u...      1              7   \n",
       "3  Works great, but I turned off all voice prompt...      1             23   \n",
       "4  Dtay away from this app! The app never turned ...      1              4   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0                1.1.5  2021-10-28 15:06:54   \n",
       "1                1.1.5  2021-01-02 17:57:46   \n",
       "2                1.1.5  2021-01-02 13:50:24   \n",
       "3                1.2.1  2021-06-06 12:13:53   \n",
       "4                  NaN  2020-01-18 17:37:08   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0                                                NaN                  NaN   \n",
       "1                                                NaN                  NaN   \n",
       "2                                                NaN                  NaN   \n",
       "3  Hi John, sorry for the inconvenience.\\nYou can...  2021-06-11 10:17:13   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "       sortOrder                                              appId  \n",
       "0  most_relevant  steptracker.healthandfitness.walkingtracker.pe...  \n",
       "1  most_relevant  steptracker.healthandfitness.walkingtracker.pe...  \n",
       "2  most_relevant  steptracker.healthandfitness.walkingtracker.pe...  \n",
       "3  most_relevant  steptracker.healthandfitness.walkingtracker.pe...  \n",
       "4  most_relevant  steptracker.healthandfitness.walkingtracker.pe...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/app_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358daf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1ce8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_to_sentiment(score):\n",
    "    score = int(score)\n",
    "    if score <= 2:\n",
    "        return 1\n",
    "    elif score == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "df['sentiment_score'] = df['score'].apply(score_to_sentiment)\n",
    "df['sentiment']=df['sentiment_score'].replace({1:'negative',0:'neutral',2:'positive'})\n",
    "df['sentiment'].value_counts().plot(kind='bar')\n",
    "classes = [ 'neutral','negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40958545",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5370fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['content'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad89ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cleaner(tweet):\n",
    "#    tweet = re.sub(\"[^a-zA-Z]\",\" \",tweet)\n",
    "#    tweet = re.sub(r\"(?:\\|http?\\://\\n|https?\\://|www)\\S+\", \"\", tweet)\n",
    "#    tweet = \" \".join(tweet.split())\n",
    "#    review= tweet.lower()\n",
    "#    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "#         if w.lower() in words or not w.isalpha())\n",
    "#    return tweet\n",
    "#df['tweet_cleaned'] = df['tweet'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2748526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cleaner(content):\n",
    "#    content = re.sub(\"[^a-zA-Z]\",\" \",content)\n",
    "#    #content = re.sub(r\"(?:\\|http?\\://\\n|https?\\://|www)\\S+\", \"\", tweet)\n",
    "#    content = \" \".join(content.split())\n",
    "#    content= content.lower()\n",
    "#    #content = [lemmatizer.lemmatize(word) for word in content if not word in stopwords.words('english')]\n",
    "#    content = \" \".join(w for w in nltk.wordpunct_tokenize(content) \\\n",
    "#         if w.lower() in words or not w.isalpha())\n",
    "#    return content\n",
    "#df['content_cleaned'] = df['content'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e0ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = 'bert-base-cased'\n",
    "#bert = AutoModel.from_pretrained(pretrained_model)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = 'I am building a project in NLP using bert'\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=16,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "encoding.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoding['attention_mask'][0]))\n",
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a468c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3f548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add447aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "for content in df.content:\n",
    "    \n",
    "  tokens = tokenizer.encode(content, max_length=512,truncation=True)\n",
    "  token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce794d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 200]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f12371",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4898f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content, temp_content,train_sentiments,temp_sentiments= train_test_split(df['content'],df['sentiment_score'],test_size=0.1,random_state=RANDOM_SEED, stratify=df['sentiment'])\n",
    "val_content,test_content,val_sentiments,test_sentiments=train_test_split(temp_content,temp_sentiments,test_size=0.2,random_state=RANDOM_SEED,stratify=temp_sentiments)\n",
    "print(train_content.shape)\n",
    "print(val_content.shape)\n",
    "print(test_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=16,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "encoding.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(content):\n",
    "    # tokenize and encode sequences in the training set\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        content.tolist(),\n",
    "        add_special_tokens=True,\n",
    "        max_length = max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train=tokenize_and_encode(train_content)\n",
    "tokens_val=tokenize_and_encode(val_content)\n",
    "tokens_test=tokenize_and_encode(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a64df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(tokens, sentiments):\n",
    "    sequence = torch.tensor(tokens['input_ids'])\n",
    "    mask = torch.tensor(tokens['attention_mask'])\n",
    "    y = torch.tensor(sentiments.tolist())\n",
    "    return sequence, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a98ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence,train_mask,train_y=convert_to_tensor(tokens_train,train_sentiments)\n",
    "val_sequence,val_mask,val_y=convert_to_tensor(tokens_val,val_sentiments)\n",
    "test_sequence,test_mask,test_y=convert_to_tensor(tokens_test,test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c986ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_sentiment(score):\n",
    "    score = int(score)\n",
    "    if score <= 2:\n",
    "        return 1\n",
    "    elif score == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "df['sentiment_score'] = df['score'].apply(score_to_sentiment)\n",
    "df['sentiment']=df['sentiment_score'].replace({1:'negative',0:'neutral',2:'positive'})\n",
    "df['sentiment'].value_counts().plot(kind='bar')\n",
    "classes = [ 'neutral','negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68dec400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name=\"bert-base-cased\", batch_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        dataset = pd.read_csv('sentiment_app_reviews.csv')[:300]\n",
    "        train_data, val_data=train_test_split(dataset,test_size=0.2,random_state=RANDOM_SEED, stratify=dataset['sentiment'])\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        \n",
    "    def tokenize_data(self, sample):\n",
    "        # processing the data\n",
    "        return self.tokenizer(\n",
    "            sample,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "        )\n",
    "    \n",
    " \n",
    "    def setup(self, stage=None):\n",
    "        # we set up only relevant datasets when stage is specified\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            #z=tokenize_data(df.apply(str))\n",
    "            self.train_data = self.train_data['content'].map(self.tokenize_data)\n",
    "            \n",
    "            #self.train_data.set_format(\n",
    "            #    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            #)\n",
    "\n",
    "            self.val_data = self.val_data['content'].map(self.tokenize_data)\n",
    "            #self.val_data.set_format(\n",
    "           #     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            #)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2b4a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModule(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"bert-base-cased\", lr=1e-2):\n",
    "        super(SentimentModule, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.num_classes = 3\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        h_cls = outputs.last_hidden_state[:, 0]\n",
    "        logits = self.W(h_cls)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"token_type_ids\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = F.cross_entropy(logits, batch[\"token_type_ids\"])\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        val_acc = accuracy_score(preds.cpu(), batch[\"token_type_ids\"].cpu())\n",
    "        val_acc = torch.tensor(val_acc)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", val_acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe701ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataModule()\n",
    "data.prepare_data()\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=df[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee2613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(df):\n",
    "        # processing the data\n",
    "        return tokenizer(\n",
    "            df,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffeb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['content'][0])\n",
    "tokenizer(df['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67f2ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] This app is horrible! It shows you the ranking of others steps and shows you where you're ranked. Problem is, every morning by 8am, it shows that multiple people have put in 40, 000 - 80, 000 steps! There is no way that somebody has walked or jogged 20 - 40 miles by 8am, and it's multiple! It used to be accurate, but all the sudden started showing extremely high counts for people. [SEP]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(df['content'][0])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aff72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=df[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47fcba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        This app is horrible! It shows you the ranking...\n",
       "1        Everything is decent but need at option to set...\n",
       "2        Don't bother! This app is useless. 1st day I u...\n",
       "3        Works great, but I turned off all voice prompt...\n",
       "4        Dtay away from this app! The app never turned ...\n",
       "                               ...                        \n",
       "33563    Simple, easy and effective. You can choose the...\n",
       "33564    Ooh this app have been helpful to me. it is ea...\n",
       "33565                                              Amazing\n",
       "33566                                      It really helps\n",
       "33567                                               I love\n",
       "Name: content, Length: 33568, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e95ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=dx['content'].map(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9d123ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1188, 12647, 1110, 9210, 106, 1135, 2196, 1128, 1103, 5662, 1104, 1639, 3343, 1105, 2196, 1128, 1187, 1128, 112, 1231, 3616, 119, 21710, 1110, 117, 1451, 2106, 1118, 129, 2312, 117, 1122, 2196, 1115, 2967, 1234, 1138, 1508, 1107, 1969, 117, 1288, 118, 2908, 117, 1288, 3343, 106, 1247, 1110, 1185, 1236, 1115, 9994, 1144, 2045, 1137, 179, 24009, 1406, 118, 1969, 1829, 1118, 129, 2312, 117, 1105, 1122, 112, 188, 2967, 106, 1135, 1215, 1106, 1129, 8026, 117, 1133, 1155, 1103, 4962, 1408, 4000, 4450, 1344, 10664, 1111, 1234, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "270e8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = torch.utils.data.DataLoader(q, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5acca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x15e917cb130>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca69fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d06ec44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [input_ids, token_type_ids, attention_mask]\n",
       "1      [input_ids, token_type_ids, attention_mask]\n",
       "2      [input_ids, token_type_ids, attention_mask]\n",
       "3      [input_ids, token_type_ids, attention_mask]\n",
       "4      [input_ids, token_type_ids, attention_mask]\n",
       "                          ...                     \n",
       "295    [input_ids, token_type_ids, attention_mask]\n",
       "296    [input_ids, token_type_ids, attention_mask]\n",
       "297    [input_ids, token_type_ids, attention_mask]\n",
       "298    [input_ids, token_type_ids, attention_mask]\n",
       "299    [input_ids, token_type_ids, attention_mask]\n",
       "Name: labels, Length: 300, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.rename('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03854c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [input_ids, token_type_ids, attention_mask]\n",
       "1      [input_ids, token_type_ids, attention_mask]\n",
       "2      [input_ids, token_type_ids, attention_mask]\n",
       "3      [input_ids, token_type_ids, attention_mask]\n",
       "4      [input_ids, token_type_ids, attention_mask]\n",
       "                          ...                     \n",
       "295    [input_ids, token_type_ids, attention_mask]\n",
       "296    [input_ids, token_type_ids, attention_mask]\n",
       "297    [input_ids, token_type_ids, attention_mask]\n",
       "298    [input_ids, token_type_ids, attention_mask]\n",
       "299    [input_ids, token_type_ids, attention_mask]\n",
       "Name: content, Length: 300, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac31bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in q:\n",
    "    print(i['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b634d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adf9dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | bert | BertModel | 108 M \n",
      "1 | W    | Linear    | 2.3 K \n",
      "-----------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.250   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d49a7da2e43fc9a635de184c18e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "38",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 38",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SentimentModule()\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m      8\u001b[0m     gpus\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m      9\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     10\u001b[0m     fast_dev_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:499\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch()\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_dispatch()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:546\u001b[0m, in \u001b[0;36mTrainer.dispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:73\u001b[0m, in \u001b[0;36mAccelerator.start_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:114\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainer\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:637\u001b[0m, in \u001b[0;36mTrainer.run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loop\u001b[38;5;241m.\u001b[39mon_train_epoch_start(epoch)\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# run train epoch\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_steps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_steps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step:\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py:484\u001b[0m, in \u001b[0;36mTrainLoop.run_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m should_check_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    482\u001b[0m val_loop_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (batch, is_last_batch) \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mbatch_idx \u001b[38;5;241m=\u001b[39m batch_idx\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;66;03m# ------------------------------------\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;66;03m# TRAINING_STEP + TRAINING_STEP_END\u001b[39;00m\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;66;03m# ------------------------------------\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\profiler\\profilers.py:82\u001b[0m, in \u001b[0;36mBaseProfiler.profile_iterable\u001b[1;34m(self, iterable, action_name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart(action_name)\n\u001b[1;32m---> 82\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop(action_name)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:47\u001b[0m, in \u001b[0;36mDataConnector._with_is_last\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"Pass through values from the given iterable with an added boolean indicating if this is the last item.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03mSee `https://stackoverflow.com/a/1630350 <https://stackoverflow.com/a/1630350>`_\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[1;32m---> 47\u001b[0m last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# yield last and has next\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m last, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:470\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Fetches the next batch from multiple data loaders\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader_iters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:484\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.request_next_batch\u001b[1;34m(loader_iters)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest_next_batch\u001b[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m    Return the batch of data from multiple iterators.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:84\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Breaking condition\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype) \u001b[38;5;129;01mand\u001b[39;00m (wrong_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Recursively apply to collection items\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 38"
     ]
    }
   ],
   "source": [
    "#data = DataModule()\n",
    "data = DataModule()\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "model = SentimentModule()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=(1 if torch.cuda.is_available() else 0),\n",
    "    max_epochs=1,\n",
    "    fast_dev_run=True,\n",
    ")\n",
    "trainer.fit(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48ac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2873299",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=16,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(df,test_size=0.1,random_state=RANDOM_SEED, stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'].value_counts()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8262542",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'].value_counts()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeb7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content, temp_content,train_sentiments,temp_sentiments= train_test_split(df['content'],df['sentiment_score'],test_size=0.1,random_state=RANDOM_SEED, stratify=df['sentiment'])\n",
    "val_content,test_content,val_sentiments,test_sentiments=train_test_split(temp_content,temp_sentiments,test_size=0.2,random_state=RANDOM_SEED,stratify=temp_sentiments)\n",
    "print(train_content.shape)\n",
    "print(val_content.shape)\n",
    "print(test_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DataModule()\n",
    "data.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a08aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b4e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67add2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_sentiment(score):\n",
    "    score = int(score)\n",
    "    if score <= 2:\n",
    "        return 1\n",
    "    elif score == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "df['sentiment_score'] = df['score'].apply(score_to_sentiment)\n",
    "df['sentiment']=df['sentiment_score'].replace({1:'negative',0:'neutral',2:'positive'})\n",
    "df['sentiment'].value_counts().plot(kind='bar')\n",
    "classes = [ 'neutral','negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7d9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name=\"bert-base-cased\", batch_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        cola_dataset = load_dataset(\"glue\", \"cola\")\n",
    "        self.train_data = cola_dataset[\"train\"]\n",
    "        self.val_data = cola_dataset[\"validation\"]\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        # processing the data\n",
    "        return self.tokenizer(\n",
    "            example[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_data = self.train_data.map(self.tokenize_data, batched=True)\n",
    "            self.train_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "            self.val_data = self.val_data.map(self.tokenize_data, batched=True)\n",
    "            self.val_data.set_format(\n",
    "                type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_data, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3be5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47cf2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
